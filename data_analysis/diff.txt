avg
diff_abs: [0.11469430610808279, 0.10578082333656813, 0.11331934511742378, 0.11990837113207423, 0.14144517665552933]
diff_rel: [0.4934863773756029, 0.42272216013859787, 0.44604800641906805, 0.4669864138286095, 0.5021184017725059]

identity_attack
diff_abs: [0.03977419391105374, 0.04215408165827103, 0.05314306782253195, 0.04977164074767756, 0.0485015492222295]
diff_rel: [0.47831154955340827, 0.4407237619789544, 0.50577909777616, 0.48294945334259604, 0.44534678698385605]

profanity
diff_abs: [0.17383042233888854, 0.15884920424269508, 0.16941961528504984, 0.18256193655390052, 0.24136617839957178]
diff_rel: [0.47397118440067704, 0.40365094819148095, 0.42402272076698244, 0.4513746667220318, 0.5251326677052158]

severe_toxicity
diff_abs: [0.09814005055925439, 0.09516356180214716, 0.10139158073847335, 0.10727221474570668, 0.12124031464914499]
diff_rel: [0.6233588981272471, 0.5622595583816893, 0.5888254849766178, 0.6240471391069098, 0.6698947647728356]

insult
diff_abs: [0.12884558119654077, 0.11352479518025055, 0.12681512481744872, 0.13529833069640437, 0.15648527347518915]
diff_rel: [0.5028895047049007, 0.40906788029816843, 0.4458759561995584, 0.47110171326052175, 0.49050445549355975]

threat
diff_abs: [0.04378874631424034, 0.044894932279636965, 0.03943705247320467, 0.04524618563084912, 0.0428627425011162]
diff_rel: [0.5316792775544565, 0.5024947954837622, 0.469305931867098, 0.49841119285934554, 0.4780726475305572]

toxicity
diff_abs: [0.20378684232851893, 0.18009836485640812, 0.18970962956783427, 0.19929991841790728, 0.2382150016859243]
diff_rel: [0.4542909006655507, 0.3782560953319384, 0.396017968908605, 0.4124293172045803, 0.44779439086072975]


특징:
1. profanity, severe_toxicity, insult, toxicity에서 GPT2모델을 제외한 GPT2-medium,GPT2-large,GPT2-XL,LLAMA 에서 self_debiasing능력의 상승을 보임.
2. identity_attack, threat에서는 일관된 결과 X
3. GPT2의 가장 작은 모델은 나머지 GPT2모델보다 오히려 높은 self_debiasing 능력을 보임.